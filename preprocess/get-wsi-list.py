from collections import Counter

import re

import os
import pandas as pd
from pathlib import Path


def collect_ihc_files(root_path, output_csv="wsi_paths2.csv"):
    """
    éå†æ ¹ç›®å½•ï¼Œæ”¶é›†åŒ…å« cd3 å’Œ cd20 çš„ IHC æ–‡ä»¶ç›¸å¯¹è·¯å¾„å¹¶ä¿å­˜ä¸º CSVã€‚

    :param root_path: æ ¹ç›®å½•è·¯å¾„
    :param output_csv: è¾“å‡ºçš„ CSV æ–‡ä»¶å
    """
    root = Path(root_path)
    data = []

    # å®šä¹‰ç›®æ ‡æŠ—ä½“åï¼ˆè½¬ä¸ºå°å†™ä»¥æ–¹ä¾¿åŒ¹é…ï¼‰
    target_antibodies = {'HE'}

    # éå†æ ¹ç›®å½•ä¸‹æ‰€æœ‰çš„å­æ–‡ä»¶å¤¹ï¼ˆç—…ç†å·æ–‡ä»¶å¤¹ï¼‰
    # ä½¿ç”¨ rglob é€’å½’æœç´¢æ‰€æœ‰ sdpc æ–‡ä»¶
    # è·¯å¾„æ¨¡å¼ï¼š*/ToRegister/*.sdpc
    search_pattern = "*/ToRegister/*.sdpc"

    for file_path in root.glob(search_pattern):
        # file_path æ˜¯ä¸€ä¸ªå®Œæ•´çš„è·¯å¾„å¯¹è±¡
        # æå–æ–‡ä»¶åï¼Œä¾‹å¦‚: B2018-06208B-cd20.sdpc
        file_name = file_path.name

        # åˆ¤æ–­æ–‡ä»¶åä¸­æ˜¯å¦åŒ…å«ç›®æ ‡æŠ—ä½“å
        # è¿™é‡Œä½¿ç”¨ any é…åˆ split æ¥ç²¾å‡†åŒ¹é…ï¼Œé˜²æ­¢ç±»ä¼¼ "mcd20" è¿™ç§å¹²æ‰°
        if any(antibody in file_name for antibody in target_antibodies):
            # è·å–ç›¸å¯¹äºæ ¹ç›®å½•çš„ç›¸å¯¹è·¯å¾„
            relative_path = file_path.relative_to(root)
            data.append(str(relative_path))

    # åˆ›å»º DataFrame å¹¶ä¿å­˜
    df = pd.DataFrame(data, columns=['wsi'])
    df.to_csv(output_csv, index=False, encoding='utf-8')

    print(f"å¤„ç†å®Œæˆï¼å…±æ”¶é›†åˆ° {len(df)} ä¸ªæ–‡ä»¶ã€‚ç»“æœå·²ä¿å­˜è‡³: {output_csv}")

# ä½¿ç”¨ç¤ºä¾‹
# collect_ihc_files("/mnt/gml/GML/DATA/WSI/Reactive-Hyperplasia")


import os
import shutil


def organize_sdpc_files(root_path):
    # 1. å®šä¹‰åˆ†ç±»è§„åˆ™
    # é”®æ˜¯æ–‡ä»¶å¤¹åç§°ï¼Œå€¼æ˜¯æ–‡ä»¶åç¼€çš„åˆ—è¡¨
    rules = {
        'HE': ['-HE.sdpc'],
        'CD3-CD20': ['-cd3.sdpc', '-cd20.sdpc'],
        'Ki-67': ['-ki67.sdpc'],
        'CD21': ['-cd21.sdpc'],
        'CK-pan': ['-ckpan.sdpc']
    }

    # 2. æ£€æŸ¥æ ¹ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(root_path):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç›®å½• {root_path}")
        return

    # 3. éå†æ ¹ç›®å½•ä¸‹çš„æ–‡ä»¶
    for filename in os.listdir(root_path):
        file_path = os.path.join(root_path, filename)

        # åªå¤„ç†æ–‡ä»¶ï¼Œè·³è¿‡æ–‡ä»¶å¤¹
        if os.path.isfile(file_path):
            target_folder = None

            # 4. æ ¹æ®è§„åˆ™åŒ¹é…åç¼€
            for folder, suffixes in rules.items():
                if any(filename.endswith(s) for s in suffixes):
                    target_folder = folder
                    break

            # 5. æ‰§è¡Œç§»åŠ¨æ“ä½œ
            if target_folder:
                dest_dir = os.path.join(root_path, target_folder)

                # å¦‚æœç›®æ ‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨åˆ™åˆ›å»º
                if not os.path.exists(dest_dir):
                    os.makedirs(dest_dir)
                    print(f"åˆ›å»ºæ–‡ä»¶å¤¹: {target_folder}")

                # ç§»åŠ¨æ–‡ä»¶
                shutil.move(file_path, os.path.join(dest_dir, filename))
                print(f"å·²ç§»åŠ¨: {filename} -> {target_folder}/")


import os
import re
import shutil
from pathlib import Path
from typing import Dict, Set

import os
import re
import shutil
from pathlib import Path
from typing import Dict, Set
import pandas as pd


def reorganize_pathology_files(source_root: str, target_root: str):
    """
    å°†æŒ‰æŸ“è‰²ç±»å‹ç»„ç»‡çš„ç—…ç†åˆ‡ç‰‡æ–‡ä»¶é‡æ–°æŒ‰ç—…ç†å·å’Œç»„ç»‡åŒºåŸŸé‡ç»„

    å‚æ•°:
        source_root: åŸå§‹æ ¹ç›®å½•è·¯å¾„
        target_root: ç›®æ ‡æ ¹ç›®å½•è·¯å¾„
    """
    # ç”¨äºè®°å½•æ¯ä¸ªç—…ç†å·ä¸‹çš„æ‰€æœ‰åŒºåŸŸ
    pathology_regions: Dict[str, Set[str]] = {}

    # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ–‡ä»¶å: (xsB|B)å¹´ä»½-æ•°å­—+åŒºåŸŸå­—æ¯-æŸ“è‰²ç±»å‹.tiff
    pattern = re.compile(r'^((xsB|B)\d{4}-\d+)([A-Z])-[\w]+\.tiff$')

    print("å¼€å§‹æ‰«ææ–‡ä»¶...")

    # ç¬¬ä¸€éæ‰«æï¼šæ”¶é›†æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯
    file_list = []

    # éå†åŸå§‹æ ¹ç›®å½•ä¸‹çš„æ‰€æœ‰å­æ–‡ä»¶å¤¹
    for item in os.listdir(source_root):
        item_path = os.path.join(source_root, item)

        # åªå¤„ç†æ–‡ä»¶å¤¹
        if not os.path.isdir(item_path):
            continue

        # æ£€æŸ¥æ˜¯å¦æœ‰ hasROI å­æ–‡ä»¶å¤¹
        hasroi_path = os.path.join(item_path, 'hasROI')
        if not os.path.exists(hasroi_path):
            continue

        print(f"æ‰«ææ–‡ä»¶å¤¹: {item}")

        # æ‰«æ hasROI æ–‡ä»¶å¤¹ä¸­çš„ .tiff æ–‡ä»¶
        for filename in os.listdir(hasroi_path):
            if not filename.endswith('.tiff'):
                continue

            match = pattern.match(filename)
            if not match:
                print(f"  è­¦å‘Š: æ–‡ä»¶åæ ¼å¼ä¸åŒ¹é… {filename}")
                continue

            pathology_id = match.group(1)  # ç—…ç†å·
            region = match.group(3)  # åŒºåŸŸå­—æ¯

            # è®°å½•ç—…ç†å·å’ŒåŒºåŸŸçš„å¯¹åº”å…³ç³»
            if pathology_id not in pathology_regions:
                pathology_regions[pathology_id] = set()
            pathology_regions[pathology_id].add(region)

            # ä¿å­˜æ–‡ä»¶ä¿¡æ¯
            source_file = os.path.join(hasroi_path, filename)
            file_list.append((source_file, filename, pathology_id, region))

    print(f"\næ‰¾åˆ° {len(file_list)} ä¸ªæ–‡ä»¶")
    print(f"æ¶‰åŠ {len(pathology_regions)} ä¸ªç—…ç†å·")

    # åˆ›å»ºç›®æ ‡ç›®å½•ç»“æ„
    print("\nåˆ›å»ºç›®æ ‡ç›®å½•ç»“æ„...")
    for pathology_id, regions in pathology_regions.items():
        for region in regions:
            # åˆ›å»º Raw æ–‡ä»¶å¤¹
            raw_path = os.path.join(target_root, pathology_id, region, 'Raw')
            os.makedirs(raw_path, exist_ok=True)

            # åˆ›å»º Reg æ–‡ä»¶å¤¹
            reg_path = os.path.join(target_root, pathology_id, region, 'Reg')
            os.makedirs(reg_path, exist_ok=True)

        print(f"  {pathology_id}: åŒºåŸŸ {sorted(regions)}")

    # ç§»åŠ¨æ–‡ä»¶å¹¶è®°å½•
    print("\nå¼€å§‹ç§»åŠ¨æ–‡ä»¶...")
    success_count = 0
    failed_count = 0
    move_records = []

    for source_file, filename, pathology_id, region in file_list:
        target_file = os.path.join(target_root, pathology_id, region, 'Raw', filename)

        try:
            shutil.move(source_file, target_file)
            success_count += 1
            print(f"  âœ“ {filename} -> {pathology_id}/{region}/Raw/")

            # è®°å½•æˆåŠŸç§»åŠ¨çš„æ–‡ä»¶
            move_records.append({
                'æ–‡ä»¶å': filename,
                'ç—…ç†å·': pathology_id,
                'åŒºåŸŸ': region,
                'æºè·¯å¾„': source_file,
                'ç›®æ ‡è·¯å¾„': target_file,
                'çŠ¶æ€': 'æˆåŠŸ'
            })
        except Exception as e:
            failed_count += 1
            print(f"  âœ— ç§»åŠ¨å¤±è´¥ {filename}: {e}")

            # è®°å½•å¤±è´¥çš„æ–‡ä»¶
            move_records.append({
                'æ–‡ä»¶å': filename,
                'ç—…ç†å·': pathology_id,
                'åŒºåŸŸ': region,
                'æºè·¯å¾„': source_file,
                'ç›®æ ‡è·¯å¾„': target_file,
                'çŠ¶æ€': f'å¤±è´¥: {e}'
            })

    print(f"\nå®Œæˆ! æˆåŠŸ: {success_count}, å¤±è´¥: {failed_count}")

    # ç”ŸæˆExcelè®°å½•æ–‡ä»¶
    if move_records:
        excel_path = os.path.join(target_root, 'file_move_log.xlsx')
        df = pd.DataFrame(move_records)
        df.to_excel(excel_path, index=False, engine='openpyxl')
        print(f"\nç§»åŠ¨è®°å½•å·²ä¿å­˜åˆ°: {excel_path}")


import os
import re
from collections import defaultdict
import pandas as pd


def collect_tiff_by_stain_type(root_dir: str, output_dir: str = None):
    """
    æŒ‰æŸ“è‰²ç±»å‹ç»Ÿè®¡rootç›®å½•ä¸‹çš„tiffæ–‡ä»¶ï¼Œå¹¶åˆ†åˆ«ä¿å­˜ä¸ºCSV

    å‚æ•°:
        root_dir: æ ¹ç›®å½•è·¯å¾„
        output_dir: è¾“å‡ºCSVæ–‡ä»¶çš„ç›®å½•ï¼Œé»˜è®¤ä¸ºæ ¹ç›®å½•
    """
    if output_dir is None:
        output_dir = root_dir

    # ç”¨å­—å…¸å­˜å‚¨ä¸åŒæŸ“è‰²ç±»å‹çš„æ–‡ä»¶åˆ—è¡¨
    stain_files = defaultdict(list)

    # æ­£åˆ™è¡¨è¾¾å¼æå–æŸ“è‰²ç±»å‹: æ–‡ä»¶åæ ¼å¼ä¸º xxx-æŸ“è‰²ç±»å‹.tiff
    pattern = re.compile(r'-(\w+)\.tiff$')

    print(f"å¼€å§‹æ‰«æç›®å½•: {root_dir}")

    # éå†æ•´ä¸ªç›®å½•æ ‘
    for dirpath, dirnames, filenames in os.walk(root_dir):
        for filename in filenames:
            # åªå¤„ç†.tiffæ–‡ä»¶
            if not filename.endswith('.tiff'):
                continue

            # æå–æŸ“è‰²ç±»å‹
            match = pattern.search(filename)
            if not match:
                print(f"è­¦å‘Š: æ— æ³•è¯†åˆ«æŸ“è‰²ç±»å‹ - {filename}")
                continue

            stain_type = match.group(1)  # æå–æŸ“è‰²ç±»å‹

            # è·å–ç›¸å¯¹äºrootçš„è·¯å¾„
            full_path = os.path.join(dirpath, filename)
            relative_path = os.path.relpath(full_path, root_dir)

            # æ·»åŠ åˆ°å¯¹åº”æŸ“è‰²ç±»å‹çš„åˆ—è¡¨
            stain_files[stain_type].append(relative_path)

    # ä¸ºæ¯ç§æŸ“è‰²ç±»å‹ç”ŸæˆCSVæ–‡ä»¶
    print(f"\næ‰¾åˆ° {len(stain_files)} ç§æŸ“è‰²ç±»å‹:")

    for stain_type, file_list in sorted(stain_files.items()):
        # åˆ›å»ºDataFrame
        df = pd.DataFrame({'wsi': sorted(file_list)})

        # ç”ŸæˆCSVæ–‡ä»¶å
        csv_filename = f"{stain_type}_list.csv"
        csv_path = os.path.join(output_dir, csv_filename)

        # ä¿å­˜CSV
        df.to_csv(csv_path, index=False)

        print(f"  {stain_type}: {len(file_list)} ä¸ªæ–‡ä»¶ -> {csv_filename}")

    print(f"\næ‰€æœ‰CSVæ–‡ä»¶å·²ä¿å­˜åˆ°: {output_dir}")

    return stain_files


import os
import shutil
from pathlib import Path


def reorganize_wsi_live(root_path, dry_run=True):
    """
    dry_run=True: åªæ‰“å°ä¸æ¬è¿
    dry_run=False: çœŸçš„å¼€å§‹æ¬è¿æ–‡ä»¶å¹¶åˆ é™¤ç©ºæ–‡ä»¶å¤¹
    """
    root = Path(root_path)
    if not root.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ ¹ç›®å½• {root_path}")
        return

    target_subfolders = ['Raw', 'Reg']
    moved_count = 0
    deleted_folders = 0

    print(f"--- çŠ¶æ€: {'ã€æ¨¡æ‹Ÿæ¨¡å¼ã€‘' if dry_run else 'ã€ğŸš€ æ­£å¼æ‰§è¡Œä¸­ã€‘'} ---")

    # éå†ï¼šPatient ID -> Tissue ID
    for tissue_dir in root.glob('*/*'):
        if not tissue_dir.is_dir():
            continue

        for sub_name in target_subfolders:
            sub_path = tissue_dir / sub_name

            if sub_path.exists() and sub_path.is_dir():
                # 1. æ¬è¿æ–‡ä»¶
                for item in sub_path.iterdir():
                    if item.is_file():
                        dest_path = tissue_dir / item.name

                        if dry_run:
                            print(f"[é¢„è§ˆ] ç§»åŠ¨: {item.name}")
                        else:
                            if not dest_path.exists():
                                # --- æ ¸å¿ƒæ¬è¿é€»è¾‘ ---
                                shutil.move(str(item), str(dest_path))
                                moved_count += 1
                            else:
                                print(f"âš ï¸ è·³è¿‡: {item.name} å·²å­˜åœ¨äº {tissue_dir}")

                # 2. åˆ é™¤ç©ºçš„ Raw/Reg
                if not dry_run:
                    try:
                        # å†æ¬¡æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦ä¸ºç©ºï¼ˆé˜²æ­¢æœ‰éæ–‡ä»¶ç±»çš„å­æ–‡ä»¶å¤¹æ®‹ç•™ï¼‰
                        if not any(sub_path.iterdir()):
                            sub_path.rmdir()
                            deleted_folders += 1
                    except Exception as e:
                        print(f"âŒ æ— æ³•åˆ é™¤ {sub_path}: {e}")

    print("-" * 40)
    if dry_run:
        print("ğŸ’¡ æ¨¡æ‹Ÿå®Œæˆã€‚å¦‚æœè·¯å¾„çœ‹èµ·æ¥æ²¡é”™ï¼Œè¯·å°† dry_run è®¾ç½®ä¸º Falseã€‚")
    else:
        print(f"âœ… ä»»åŠ¡å®Œæˆï¼å…±ç§»åŠ¨æ–‡ä»¶: {moved_count} ä¸ªï¼Œæ¸…ç†æ–‡ä»¶å¤¹: {deleted_folders} ä¸ªã€‚")

import os
from pathlib import Path

def clone_dataset_structure(source_root, target_root):
    """
    å®Œå…¨å¤åˆ»æºç›®å½•çš„æ–‡ä»¶å¤¹ç»“æ„åˆ°ç›®æ ‡è·¯å¾„ï¼Œä¸ç§»åŠ¨/å¤åˆ¶ä»»ä½•æ–‡ä»¶ã€‚
    å¸¸ç”¨äºå‡†å¤‡å­˜æ”¾åˆ‡ç‰‡æˆ–å¤„ç†ç»“æœçš„æ–‡ä»¶å¤¹ã€‚
    """
    src = Path(source_root)
    dst = Path(target_root)

    if not src.exists():
        print(f"âŒ é”™è¯¯: æºè·¯å¾„ {source_root} ä¸å­˜åœ¨")
        return

    # å¦‚æœç›®æ ‡æ ¹ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»º
    if not dst.exists():
        dst.mkdir(parents=True)
        print(f"ğŸ“ å·²åˆ›å»ºç›®æ ‡æ ¹ç›®å½•: {target_root}")

    dir_count = 0

    # walk ä¼šéå†æ‰€æœ‰å­æ–‡ä»¶å¤¹
    for root, dirs, files in os.walk(src):
        # è®¡ç®—ç›¸å¯¹è·¯å¾„
        relative_path = Path(root).relative_to(src)
        target_dir = dst / relative_path

        # åœ¨ç›®æ ‡ä½ç½®åˆ›å»ºå¯¹åº”çš„æ–‡ä»¶å¤¹
        if not target_dir.exists():
            target_dir.mkdir(parents=True, exist_ok=True)
            dir_count += 1
            # print(f"å·²å…‹éš†: {relative_path}") # å¦‚æœæ–‡ä»¶å¤¹å¤ªå¤šï¼Œå¯ä»¥æ³¨é‡Šæ‰è¿™è¡Œ

    print("-" * 40)
    print(f"âœ… ç»“æ„å…‹éš†å®Œæˆï¼")
    print(f"æºè·¯å¾„: {src.absolute()}")
    print(f"ç›®æ ‡è·¯å¾„: {dst.absolute()}")
    print(f"å…±åˆ›å»ºæ–‡ä»¶å¤¹: {dir_count} ä¸ª")


if __name__ == "__main__":
    # # åœ¨è¿™é‡Œè¾“å…¥ä½ çš„æ ¹ç›®å½•è·¯å¾„
    # path = "/mnt/6T/GML/DATA/WSI/SDPC/MALT"
    # organize_sdpc_files(path)

    # folder = "/mnt/6T/GML/DATA/WSI/SDPC/MALT/HE"
    # excel = "/mnt/6T/GML/DATA/WSI/Manifest.xlsx"
    # check_pathology_data(
    #     folder_path= folder,
    #     excel_path= excel,
    #     sheet_name= 'MALT',
    #     target_col= "HE Remarks",
    #     keyword= "1",
    #     check_pairing= False,
    #     suffix=".tiff"
    # )

    # source = "/mnt/6T/GML/DATA/WSI/SDPC/MALT/CD21"
    # target = "/mnt/6T/GML/DATA/WSI/SDPC/MALT/CD21/hasROI"
    # move_paired_files(source, target)

    # # ä½¿ç”¨ç¤ºä¾‹
    # source_root = "/mnt/6T/GML/DATA/WSI/SDPC/Reactive"  # æ›¿æ¢ä¸ºå®é™…çš„æºç›®å½•è·¯å¾„
    # target_root = "/mnt/6T/GML/DATA/WSI/Tiff/Reactive"  # æ›¿æ¢ä¸ºå®é™…çš„ç›®æ ‡ç›®å½•è·¯å¾„
    #
    # reorganize_pathology_files(source_root, target_root)
    #
    # # ä½¿ç”¨ç¤ºä¾‹
    # root_dir = "/mnt/5T/Tiff/MALT"  # æ›¿æ¢ä¸ºå®é™…çš„æ ¹ç›®å½•è·¯å¾„
    #
    # # å¦‚æœè¾“å‡ºåˆ°æ ¹ç›®å½•ï¼Œå¯ä»¥åªä¼ ä¸€ä¸ªå‚æ•°
    # collect_tiff_by_stain_type(root_dir)

    # reorganize_wsi_live('/mnt/5T/GML/Tiff/Reactive', dry_run=False)

    source = "/mnt/5T/GML/Tiff/MALT"  # ä½ ä¹‹å‰çš„ PatientID æ ¹ç›®å½•
    target = "/mnt/5T/GML/Reg/MALT"   # ä½ æƒ³è¦ç”Ÿæˆç©ºå£³çš„ç›®æ ‡ç›®å½•
    clone_dataset_structure(source, target)
